#+title: Tezos Context Lima Performance Audit
#+author: Irmin Team
#+STARTUP: inlineimages

* Introduction

The Octez ~tezos-context~ package maintains an on-disk representation of Tezos blocks. It is implemented using [[https://irmin.org/][Irmin]] and the purpose-built Irmin backend [[https://mirage.github.io/irmin/irmin-pack/index.html][~irmin-pack~]].

Performance of ~tezos-context~ is important for overall performance of Octez and previous improvments in ~irmin-pack~ have led to [[https://tarides.com/blog/2022-04-26-lightning-fast-with-irmin-tezos-storage-is-6x-faster-with-1000-tps-surpassed/][major performance improvements in Octez]].

This report contains an audit of the ~irmin-pack~ storage backend used by Tezos Octez. We investigate the performance of individual sub-components as well as access patterns used by Tezos.

** Overview of ~irmin-pack~

Irmin is a content-addressable data store similar to Git. Data is stored in trees where nodes and leaves of the trees are identified by their cryptographic hash. At it's core Irmin is a store of content-addressed objects (nodes and leaves).

~irmin-pack~ is a space-optimized Irmin backend inspired by Git packfiles that is currently used in Octez.

Conceptually ~irmin-pack~ stores content-addressed objects to an append-only file. A persistent datastructure called the index is used to map hashes to positions in the append-only file.

* Sub-components
** Index

The index is a persistent datastructure that maps the hash of an object to its offset in the append-only pack file.

Since Irmin version 3.0.0 objects in the pack file hold direct references to other objects in the pack file [[[https://github.com/mirage/irmin/pull/1659][irmin #1659]]] this removes the necessity to always query the index when traversing objects. This also allows a smaller index as now only top-level objects (i.e. commits) need to be in the index [[[https://github.com/mirage/irmin/pull/1664][irmin #1664]]]. This is called ~minimal~ indexing and has allowed [[https://tarides.com/blog/2022-04-26-lightning-fast-with-irmin-tezos-storage-is-6x-faster-with-1000-tps-surpassed][considerable performance improvements for the Octez storage layer]].

The index datastructure is split into two major parts: the log and the data. The log is a small and bounded structure that holds recently-added bindings. The log is kept in memory after initialization. The data part holds older bindings. When a certain number of bindings are added to the log, the bindings are merged with the bindings in the data part. The datastructure is similar to a two-level [[https://en.wikipedia.org/wiki/Log-structured_merge-tree][Log-structured merge-tree]].

The default number of bindings to keep in the log before moving them to the data part [[https://gitlab.com/tezos/tezos/-/blob/master/src/lib_context/helpers/env.ml#L41-45][in Octez]] and [[https://github.com/mirage/irmin/blob/main/src/irmin-pack/conf.mli#L93-L94][in ~irmin-pack~]] is set to 2_500_000.

*** Rolling and full node

We observe that rolling and full nodes [[https://tezos.gitlab.io/user/history_modes.html#history-mode-additional-cycles][keep a default of 6 cycles]] which corresponds to about 98_304 blocks ([[https://tezos.gitlab.io/active/proof_of_stake.html#ps-constants][16_834 blocks per cycle]]) or, in Irmin terminology, to about 98_304 commits. Rolling and full nodes will by default never create a data part and every index lookup performed is an in-memory operation.

A quick check confirms this:

#+begin_src shell :exports both
  dune exec audits/index/count_bindings.exe -- inputs/store-level-3081990/
#+end_src

#+RESULTS:
: Number of bindings in Index: 100005

Note that the number of bindings in the index is slightly higher than 98_304 as the store also contains orphaned commits.

*** Archive node

Tezos archive nodes hold the full history since genesis. When using minimal indexing references to at most 2_500_000 commits/blocks are kept in the log of the index. In July 2022 the Tezos block chain reached that block height. So since at least July 2022 the index of archive nodes will also have a ~data~ part.

Archive nodes that were bootstrapped before the new minimal indexing strategy was adopted have many more entries in the index:

#+begin_src shell :exports both
  dune exec audits/index/count_bindings.exe -- inputs/archive-node-index/
#+end_src

#+RESULTS:
: Number of bindings in Index: 2036584177


Archive nodes bootstrapped before the new minimal indexing strategy was adopted use around 90GiB of space just for the index structure.

*** Find Performance

We measure the performance of index lookups by creating an empty index structure with same parameters as used in Tezos Octez (key size of 30 bytes, value size of 13 bytes and log size of 2_500_000), adding ~c~ random bindings and performing ~c~ lookups for random bindings. We use the [[https://github.com/LexiFi/landmarks][LexiFi/landmarks]] library to measure performance in CPU cycles (as well as system time).

#+tblname: find-performance
| ^ |   count |           cpu_time |  sys_time | cpu_time per entry |
|---+---------+--------------------+-----------+--------------------|
| # |  250000 |  2132773826.000000 |  1.126439 |          8531.0953 |
| # |  500000 |  4009158441.000000 |  2.119049 |          8018.3169 |
| # | 1000000 |  8235106179.000000 |  4.351689 |          8235.1062 |
| # | 2000000 | 16838605030.000000 |  8.893822 |          8419.3025 |
| # | 2499999 | 20421445765.000000 | 10.791509 |          8168.5816 |
| # | 2500001 | 23511451504.000000 | 12.446721 |          9404.5768 |
| # | 3000000 | 31077192851.000000 | 16.442429 |          10359.064 |
| # | 4000000 | 39358430251.000000 | 20.823590 |          9839.6076 |
| # | 5000000 | 48122118368.000000 | 25.448949 |          9624.4237 |
| # | 6000000 | 60941841080.000000 | 32.247097 |          10156.974 |
| # | 7000000 | 72898690458.000000 | 38.564382 |          10414.099 |
#+TBLFM: $5=$3/$2

#+begin_src gnuplot :var data=find-performance :exports results :file find-performance.png
  reset

  set title "Index.find performance"

  set xlabel "number of entries"
  set format x '%.0f'

  set arrow from 2500000, graph 0 to 2500000, graph 1 nohead lc 2 title "log size"

  set ylabel "CPU cycles"

  plot data u 1:4 with point lw 2 title 'CPU cycles per entry'
#+end_src

#+RESULTS:
[[file:find-performance.png]]

We note a sharp increase in CPU cycles needed to lookup an entry when the number of bindings jumps over the log size (2_500_000). The lookup performance stays relatively constant at a higher level for up to 7_000_000 entries.

*** Conclusion

With the currently implemented minimal indexing scheme no performance issues are expected when using the default Tezos Octez configurations. For nodes running in history modes "rolling" and "full" the index is an in-memory structure. For archive nodes, no considerable performance degradation is expected up to at least block level 7_000_000.

Archive nodes that were bootstrapped using non-minimal indexing have a very large index structure. For better disk-usage it is recommended to re-bootstrap these nodes using minimal indexing.

** TODO Dict
* TODO IO Activity

In order to measure real disk IO accesses we add some [[https://github.com/mirage/irmin/pull/2250][instrumentation to irmin-pack]] that allows us to measure how many bytes are read/written to individual files in how many system calls.

When replaying a trace of 100_000 Tezos blocks we observe a total disk activity of:

- 55GiB of data read with 46_354_744_574 system calls (average size of read is 61 bytes).
- 43GiB of data written with 406_103 system calls (average size of write is 111 KiB).

See [[./audits/io/README.org]].

* TODO Entropy Analysis

Use radare2 or other tools to measure entropy of files on-disk. This is an indication of how well compressed the pack files are.

* Context structure and access patterns
** TODO Content Size distribution

#+tblname: context-content-size
| Exponent |    Count |
|----------+----------|
|        0 |   596661 |
|        1 | 23722650 |
|        2 | 38698770 |
|        3 |  1125580 |
|        4 |  3131048 |
|        5 |  4194650 |
|        6 |  7477058 |
|        7 |   532486 |
|        8 |   194262 |
|        9 |    35410 |
|       10 |    35600 |
|       11 |    71535 |
|       12 |     4289 |
|       13 |     2583 |
|       14 |      260 |
|       15 |        9 |
|       16 |        1 |
|       17 |        3 |
|       18 |        7 |

#+begin_src gnuplot :var data=context-content-size :exports results :file context-content-size.png
  reset

  set title "Context Content Size"
  set style data histogram

  plot data using 2:xticlabels(1)
#+end_src

#+RESULTS:
[[file:context-content-size.png]]

** TODO Access Patterns
* Modern hardware and asynchronous APIs

Modern PCIe-attached solid-state drives (SSDs) offer high throughput and
large capacity at low cost. They are exposed to the system using the same block-based APIs as traditional disks or SSDs attached via serial buses. However, in order to utilize the full performance of such modern hardware, the way I/O operations are performed requires rethinking.

We do some explorations on how performance could be improved using modern hardware and APIs using the [[https://fio.readthedocs.io/en/latest/fio_doc.html][fio]] tool. All tests were run on a StarLabs Starbook Mk VI with an AMD Ryzen 7 8-core 5800U processor and a PCIe3-connected 960GiB SSD.

** Baseline ~irmin-pack.unix~ reads

We attempt to simulate a similar behaviour as is currently implemented by ~irmin-pack.unix~.

From observations we have that:

- During the processing of a single Tezos Block about 3.5 MiB is read from disk
- Average access size is between 50-100 bytes
- ~irmin-pack.unix~ uses the `pread` system calls from a single thread

A ~fio~ job description that simulates such an access pattern:

#+begin_src ini :tangle baseline-reads.ini
[global]
rw=randread
filename=/home/adatario/dev/tclpa/.git/annex/objects/gx/17/SHA256E-s3691765475--13300581f2404cc24774da8615a5a3d3f0adb7d68c4c8034c4fa69e727706000/SHA256E-s3691765475--13300581f2404cc24774da8615a5a3d3f0adb7d68c4c8034c4fa69e727706000

[job1]
ioengine=psync
rw=randread
blocksize_range=50-300
size=3500000B
loops=100
#+end_src

#+begin_src shell :exports both :results output code
  fio baseline-reads.ini
#+end_src

#+RESULTS:
#+begin_src shell
job1: (g=0): rw=randread, bs=(R) 50B-300B, (W) 50B-300B, (T) 50B-300B, ioengine=psync, iodepth=1
fio-3.33
Starting 1 process

job1: (groupid=0, jobs=1): err= 0: pid=42484: Fri May 19 14:18:35 2023
  read: IOPS=230k, BW=29.8MiB/s (31.2MB/s)(334MiB/11209msec)
    clat (nsec): min=210, max=4069.4k, avg=4129.23, stdev=21131.34
     lat (nsec): min=230, max=4070.1k, avg=4154.08, stdev=21135.27
    clat percentiles (nsec):
     |  1.00th=[   221],  5.00th=[   231], 10.00th=[   231], 20.00th=[   231],
     | 30.00th=[   241], 40.00th=[   241], 50.00th=[   241], 60.00th=[   251],
     | 70.00th=[   310], 80.00th=[   330], 90.00th=[   362], 95.00th=[   612],
     | 99.00th=[123392], 99.50th=[130560], 99.90th=[136192], 99.95th=[136192],
     | 99.99th=[148480]
   bw (  KiB/s): min=27526, max=33845, per=99.84%, avg=30444.41, stdev=2900.78, samples=22
   iops        : min=207124, max=255516, avg=229381.59, stdev=22386.75, samples=22
  lat (nsec)   : 250=55.59%, 500=37.79%, 750=2.44%, 1000=0.65%
  lat (usec)   : 2=0.13%, 4=0.13%, 10=0.01%, 20=0.01%, 100=0.05%
  lat (usec)   : 250=3.23%, 500=0.01%, 750=0.01%
  lat (msec)   : 10=0.01%
  cpu          : usr=7.52%, sys=8.17%, ctx=84419, majf=0, minf=12
  IO depths    : 1=100.0%, 2=0.0%, 4=0.0%, 8=0.0%, 16=0.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwts: total=2575300,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=1

Run status group 0 (all jobs):
   READ: bw=29.8MiB/s (31.2MB/s), 29.8MiB/s-29.8MiB/s (31.2MB/s-31.2MB/s), io=334MiB (350MB), run=11209-11209msec

Disk stats (read/write):
    dm-1: ios=84008/120, merge=0/0, ticks=9396/0, in_queue=9396, util=94.84%, aggrios=84402/120, aggrmerge=0/0, aggrticks=9400/0, aggrin_queue=9400, aggrutil=94.70%
    dm-0: ios=84402/120, merge=0/0, ticks=9400/0, in_queue=9400, util=94.70%, aggrios=84402/99, aggrmerge=0/21, aggrticks=8827/5, aggrin_queue=8833, aggrutil=94.70%
  nvme0n1: ios=84402/99, merge=0/21, ticks=8827/5, in_queue=8833, util=94.70%
#+end_src

We observe a read bandwidth of about 30MiB/s. This seems to match up with the read performance observed when replaying a Tezos trace.

** Multicore

We simulate the usage of multiple CPU cores with following ~fio~ job description:

#+begin_src ini :tangle multiple-threads-pread.ini
[global]
rw=randread
filename=/home/adatario/dev/tclpa/.git/annex/objects/gx/17/SHA256E-s3691765475--13300581f2404cc24774da8615a5a3d3f0adb7d68c4c8034c4fa69e727706000/SHA256E-s3691765475--13300581f2404cc24774da8615a5a3d3f0adb7d68c4c8034c4fa69e727706000
loops=100
group_reporting
thread

[job1]
ioengine=psync
rw=randread
blocksize_range=50-300
size=3500000 / N
numjobs= N
#+end_src

Where ~N~ is the number of threads used.

We observe following read bandwidth:

| Number of Threads | Read bandwidth (MiB/s) |
|-------------------+------------------------|
|                 1 |                   23.4 |
|                 2 |                   72.8 |
|                 3 |                    102 |
|                 4 |                    127 |
|                 5 |                    147 |
|                 6 |                    163 |
|                 7 |                    175 |
|                 8 |                    167 |
|                 9 |                    175 |
|                10 |                    172 |


Increasing the number of threads/CPU cores utilized seems to lead to considerable performance improvements.

** TODO CPU boundness

| CPU Frequency           | 3.40GHz  | 2.5GHz        | 1.5GHz        |
| CPU time elapsed        | 73m27s   | 103m26s 141%  | 194m37s 265%  |
| Wall time elapsed       | 76m08s   | 103m24s 136%  | 194m28s 255%  |
| TZ-transactions per sec | 1043.919 | 741.288  71%  | 393.969  38%  |
| TZ-operations per sec   | 6818.645 | 4841.928  71% | 2573.316  38% |

** TODO Reducing CPU load by disabling OS buffering

Operating systems implement their own cache mechanism for disk access. This [[https://db.in.tum.de/~leis/papers/leanstore.pdf][can cause additional CPU cycles]] which are unnecessary as ~irmin-pack.unix~ implements it's own cache.

We can disable the operating system to cache blocks by using the [[https://linux.die.net/man/2/fadvise][~fadvise~]] system call with ~FADV_NOREUSE~. This will prevent the operating system from maintaining blocks in cache, thus saving CPU cycles.

We can tell ~fio~ to do this with the ~fadvise_hint~ option:

#+begin_src ini :tangle fadvise-noreuse.ini
[global]
rw=randread
filename=/home/adatario/dev/tclpa/.git/annex/objects/gx/17/SHA256E-s3691765475--13300581f2404cc24774da8615a5a3d3f0adb7d68c4c8034c4fa69e727706000/SHA256E-s3691765475--13300581f2404cc24774da8615a5a3d3f0adb7d68c4c8034c4fa69e727706000

[job1]
ioengine=psync
rw=randread
blocksize_range=50-300
size=3500000B
loops=100
fadvise_hint=noreuse
#+end_src

This seems to be a considerable performance improvement that can be implemented fairly easily.

** Asynchronous I/O

In order to illustrate the capabilities of modern hardware we run ~fio~ using the Linux [[https://en.wikipedia.org/wiki/Io_uring][io_uring]] API. This allows asynchronous I/O operations.

We also increase size of the blocks read from a few bytes to 64KiB. This increases latency for individual reads, but allows much higher bandwidth.

#+begin_src ini :tangle read-io_uring.ini
[global]
rw=randread
filename=/home/adatario/dev/tclpa/.git/annex/objects/gx/17/SHA256E-s3691765475--13300581f2404cc24774da8615a5a3d3f0adb7d68c4c8034c4fa69e727706000/SHA256E-s3691765475--13300581f2404cc24774da8615a5a3d3f0adb7d68c4c8034c4fa69e727706000
loops=100
group_reporting
thread

[job1]
ioengine=io_uring
iodepth=16
rw=randread
blocksize=64KiB
size=100MiB
numjobs=8
#+end_src

#+begin_src shell :exports both :results output code
  fio read-io_uring.ini
#+end_src

#+RESULTS:
#+begin_src shell
job1: (g=0): rw=randread, bs=(R) 62.5KiB-62.5KiB, (W) 62.5KiB-62.5KiB, (T) 62.5KiB-62.5KiB, ioengine=io_uring, iodepth=16
...
fio-3.33
Starting 8 threads

job1: (groupid=0, jobs=8): err= 0: pid=44365: Fri May 19 14:25:25 2023
  read: IOPS=147k, BW=8955MiB/s (9390MB/s)(74.5GiB/8517msec)
    slat (nsec): min=290, max=9700.4k, avg=9392.25, stdev=73806.67
    clat (nsec): min=130, max=23784k, avg=767189.99, stdev=1005905.48
     lat (usec): min=4, max=23786, avg=776.58, stdev=1007.13
    clat percentiles (usec):
     |  1.00th=[   17],  5.00th=[   30], 10.00th=[   43], 20.00th=[   62],
     | 30.00th=[   83], 40.00th=[  125], 50.00th=[  215], 60.00th=[  400],
     | 70.00th=[  914], 80.00th=[ 1795], 90.00th=[ 2278], 95.00th=[ 2606],
     | 99.00th=[ 3884], 99.50th=[ 4490], 99.90th=[ 6390], 99.95th=[ 7439],
     | 99.99th=[10028]
   bw (  MiB/s): min= 7688, max=10172, per=100.00%, avg=9047.06, stdev=83.12, samples=129
   iops        : min=125968, max=166674, avg=148226.72, stdev=1361.83, samples=129
  lat (nsec)   : 250=0.01%, 500=0.01%, 750=0.01%, 1000=0.01%
  lat (usec)   : 2=0.01%, 4=0.02%, 10=0.10%, 20=1.72%, 50=11.80%
  lat (usec)   : 100=21.71%, 250=17.36%, 500=10.21%, 750=4.71%, 1000=3.36%
  lat (msec)   : 2=12.41%, 4=15.67%, 10=0.88%, 20=0.01%, 50=0.01%
  cpu          : usr=2.68%, sys=14.62%, ctx=559563, majf=0, minf=0
  IO depths    : 1=0.1%, 2=0.1%, 4=0.3%, 8=0.5%, 16=99.0%, 32=0.0%, >=64=0.0%
     submit    : 0=0.0%, 4=100.0%, 8=0.0%, 16=0.0%, 32=0.0%, 64=0.0%, >=64=0.0%
     complete  : 0=0.0%, 4=99.9%, 8=0.0%, 16=0.1%, 32=0.0%, 64=0.0%, >=64=0.0%
     issued rwts: total=1249600,0,0,0 short=0,0,0,0 dropped=0,0,0,0
     latency   : target=0, window=0, percentile=100.00%, depth=16

Run status group 0 (all jobs):
   READ: bw=8955MiB/s (9390MB/s), 8955MiB/s-8955MiB/s (9390MB/s-9390MB/s), io=74.5GiB (80.0GB), run=8517-8517msec

Disk stats (read/write):
    dm-1: ios=345735/95, merge=0/0, ticks=597292/4, in_queue=597296, util=98.72%, aggrios=349972/95, aggrmerge=0/0, aggrticks=599656/4, aggrin_queue=599660, aggrutil=98.56%
    dm-0: ios=349972/95, merge=0/0, ticks=599656/4, in_queue=599660, util=98.56%, aggrios=349972/87, aggrmerge=0/8, aggrticks=542294/6, aggrin_queue=542303, aggrutil=97.77%
  nvme0n1: ios=349972/87, merge=0/8, ticks=542294/6, in_queue=542303, util=97.77%
#+end_src

We observe a read bandwidth of about 9GiB/s which illustrates the capabilities of modern hardware.

* Conclusion
